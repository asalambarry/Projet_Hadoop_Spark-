{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504ee6d4-feb6-4ab0-b7fb-e17163e22a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .set(\"spark.driver.memory\", \"4g\") \\\n",
    "    .set(\"spark.executor.memory\", \"4g\") \\\n",
    "    .set(\"spark.executor.cores\", \"2\") \\\n",
    "    .set(\"spark.driver.maxResultSize\", \"2g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24635d85-087c-4bba-8e1e-4be45c1944da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/04 20:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataProject\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c47f821-866a-4702-b969-37efcc2a0839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movies_df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/datasets/movie.csv\",\n",
    "    header=True,        \n",
    "    inferSchema=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a4010e-3052-40d1-9315-1f18aa068439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, title: string, genres: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c22ebf5-fcee-4b59-ba18-445274dc3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/datasets/rating.csv\",\n",
    "    header=True,        \n",
    "    inferSchema=True    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6735f9-1083-442a-8737-5db7e8a1cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da0fb9b-f0a2-45db-845b-3f259113db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c3c878-37bd-464c-8b1a-6f4b7bc88476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('movieId', IntegerType(), True), StructField('title', StringType(), True), StructField('genres', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "movie_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)\n",
    "])\n",
    "print(movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc13a52-dce1-4755-868b-896feb69ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('userId', IntegerType(), True), StructField('movie', StringType(), True), StructField('rating', StringType(), True), StructField('timestamp', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "rating_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movie\", StringType(), True),\n",
    "    StructField(\"rating\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])\n",
    "print(rating_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac3ddc0-b47f-4604-a821-d1fabb700754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    148|    1|\n",
      "|    463|    1|\n",
      "|    471|    1|\n",
      "|    496|    1|\n",
      "|    833|    1|\n",
      "|   1088|    1|\n",
      "|   1238|    1|\n",
      "|   1342|    1|\n",
      "|   1580|    1|\n",
      "|   1591|    1|\n",
      "|   1645|    1|\n",
      "|   1829|    1|\n",
      "|   1959|    1|\n",
      "|   2122|    1|\n",
      "|   2142|    1|\n",
      "|   2366|    1|\n",
      "|   2659|    1|\n",
      "|   2866|    1|\n",
      "|   3175|    1|\n",
      "|   3749|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=========================>                                (7 + 9) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|  128|\n",
      "|   463|   80|\n",
      "|   471|  548|\n",
      "|   496|  168|\n",
      "|   833|   47|\n",
      "|  1088|   60|\n",
      "|  1238|   97|\n",
      "|  1342|   25|\n",
      "|  1580|   42|\n",
      "|  1591|   50|\n",
      "|  1645|  108|\n",
      "|  1829|  288|\n",
      "|  1959|  226|\n",
      "|  2122|  115|\n",
      "|  2142|   29|\n",
      "|  2366|   42|\n",
      "|  2659|  101|\n",
      "|  2866|  940|\n",
      "|  3175|   22|\n",
      "|  3749|   44|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movies_df.groupBy(\"movieId\").count().show()\n",
    "rating_df.groupBy(\"userId\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c87d39d-4609-45d9-a7b4-ec5c5e0c4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérification des doublouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7860b00d-4c87-48aa-ada4-7ab21175282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doublons dans movies : 27278 vs 27278\n"
     ]
    }
   ],
   "source": [
    "print(\"Doublons dans movies :\", movies_df.count(), \"vs\", movies_df.dropDuplicates().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1714a2e1-fc00-496f-a85d-09eeec165e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:23 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:24 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 26:====================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doublons dans rating : 20000263 vs 20000263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Doublons dans rating :\", rating_df.count(), \"vs\", rating_df.dropDuplicates().count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e3acf-a1aa-4088-8913-1a513a6a2e84",
   "metadata": {},
   "source": [
    "# Vérification des valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03be6427-9cb3-4646-9d69-19aa31ff7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|       |\n",
      "+-------+\n",
      "\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|       |\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan, isnull\n",
    "\n",
    "# Pour rating\n",
    "rating_df.select([col(c).isNull().alias(c) for c in rating_df.columns]).summary(\"\").show()\n",
    "\n",
    "# Pour movies\n",
    "movies_df.select([col(c).isNull().alias(c) for c in movies_df.columns]).summary(\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576c86f-4c29-4659-a2d6-097b0085ef0d",
   "metadata": {},
   "source": [
    "Fussionner les deux df avec Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a07c84-5d1f-4662-af66-ca6b102d0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "|movieId|userId|rating|          timestamp|               title|              genres|\n",
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "|      2|     1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|Adventure|Childre...|\n",
      "|     29|     1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|     32|     1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|\n",
      "|     47|     1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "|     50|     1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_movies = rating_df.join(movies_df, on=\"movieId\", how=\"inner\")\n",
    "rating_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13977bc6-3180-4c37-b51f-5ecabcf00c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ebf53-ec84-4faa-8316-33c22e6dcb70",
   "metadata": {},
   "source": [
    "#Nombre de lignes distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29591600-5178-4b64-980f-803ea9be5790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/04 20:42:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.select(\"userId\", \"movieId\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0636b235-a096-4e5c-a0bb-708aef706b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "138493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.select(\"movieId\").distinct().count()\n",
    "rating_movies.select(\"userId\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb53341-0df6-4920-aa50-3003442a59e9",
   "metadata": {},
   "source": [
    "# filtrage des notes extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05307bc-eb3d-4878-aaa7-f6968a2e6799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = rating_df.filter((col(\"rating\") >= 0.5) & (col(\"rating\") <= 5.0))\n",
    "rating_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0bd2e-7e46-49b6-b20a-87e4c4c3f367",
   "metadata": {},
   "source": [
    "# convert datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ffe875-6647-46ca-b8be-08facb7f79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2005-04-02 23:53:47|\n",
      "|2005-04-02 23:31:16|\n",
      "|2005-04-02 23:33:39|\n",
      "|2005-04-02 23:32:07|\n",
      "|2005-04-02 23:29:40|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "rating_movies = rating_movies.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "rating_movies.printSchema()\n",
    "rating_movies.select(\"timestamp\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb83249-c2a2-41f5-a7d7-3fde559094cf",
   "metadata": {},
   "source": [
    "# Importation du modèle \"ALS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faddf22c-5362-4bcd-92b0-4841231a1c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4885f46a-c1f5-46fe-af95-0ad33c736867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6ad23-8409-4fb0-82ee-ed22081a0840",
   "metadata": {},
   "source": [
    "# Données de train et test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3913391d-ba9a-417d-8292-aff9c1cd9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = rating_movies.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cba760a-9214-4fd0-bfad-11ab375f134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8231c55-326f-4651-a0ed-716d7d212a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/04 20:43:23 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    rank=10,             # nombre de facteurs latents\n",
    "    maxIter=10,          # nombre d’itérations\n",
    "    regParam=0.1,        # régularisation\n",
    "    numItemBlocks=10,    # Nombre de blocs pour paralléliser le calcul \n",
    "    nonnegative=True\n",
    ")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb536f4-2194-4e42-8961-911ec5157d45",
   "metadata": {},
   "source": [
    "# Evaluation du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02fe2f41-2efc-46b6-a135-3fa860ac1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:===================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle:\n",
      "RMSE sur le jeu de test : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"\\nPerformance du modèle:\")\n",
    "print(f\"RMSE sur le jeu de test : {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "879d2770-4d9e-4a9e-9377-bc407cc429eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 246:====================>                                  (6 + 10) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    31|      1|   3.0| 3.2316926|\n",
      "|  8947|      1|   5.0| 3.7349746|\n",
      "|  8986|      1|   4.0| 3.4628525|\n",
      "|  9027|      1|   5.0|  3.114496|\n",
      "| 17486|      1|   3.0| 3.6125379|\n",
      "| 17536|      1|   3.0| 3.5501812|\n",
      "| 17539|      1|   4.0| 3.0027003|\n",
      "| 26273|      1|   3.0|  3.175322|\n",
      "| 26309|      1|   4.5| 3.3283956|\n",
      "| 35112|      1|   5.0| 4.0773134|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.select(\"userId\", \"movieId\", \"rating\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1124f76-22c4-45e2-a974-5a6da0445fbc",
   "metadata": {},
   "source": [
    "# Suppression des Nan dans la prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a69ca48e-1e7f-40d0-8c13-497fa437ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, col\n",
    "\n",
    "predictions.filter(col(\"prediction\").isNull() | isnan(col(\"prediction\"))).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "463d30db-8611-42dc-9f39-a6587a122e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_clean = predictions.na.drop(subset=[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9196805e-bd13-408c-b118-4b15af8898eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 453:===================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la performance RMSE  : 0.8141320807718612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions_clean)\n",
    "print(f\"la performance RMSE  : {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27dd7f27-b2e9-4279-aa5b-3c5de2cdfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "model.write().overwrite().save(\"hdfs://namenode:9000/models/als\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3310c-12c0-4c7f-ab13-fac35ebbc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'userId': 16, 'movieId': 368, 'rating': 2.5, 'timestamp': 1746392638}\n",
      "Sent: {'userId': 85, 'movieId': 192, 'rating': 2.3, 'timestamp': 1746392639}\n",
      "Sent: {'userId': 21, 'movieId': 442, 'rating': 1.8, 'timestamp': 1746392640}\n",
      "Sent: {'userId': 52, 'movieId': 324, 'rating': 1.7, 'timestamp': 1746392642}\n",
      "Sent: {'userId': 69, 'movieId': 276, 'rating': 4.0, 'timestamp': 1746392643}\n",
      "Sent: {'userId': 43, 'movieId': 458, 'rating': 3.3, 'timestamp': 1746392646}\n",
      "Sent: {'userId': 29, 'movieId': 121, 'rating': 2.2, 'timestamp': 1746392647}\n",
      "Sent: {'userId': 19, 'movieId': 331, 'rating': 3.6, 'timestamp': 1746392649}\n",
      "Sent: {'userId': 8, 'movieId': 358, 'rating': 3.8, 'timestamp': 1746392650}\n",
      "Sent: {'userId': 46, 'movieId': 156, 'rating': 3.3, 'timestamp': 1746392651}\n",
      "Sent: {'userId': 2, 'movieId': 175, 'rating': 4.9, 'timestamp': 1746392652}\n",
      "Sent: {'userId': 6, 'movieId': 95, 'rating': 2.6, 'timestamp': 1746392653}\n",
      "Sent: {'userId': 15, 'movieId': 27, 'rating': 3.5, 'timestamp': 1746392654}\n",
      "Sent: {'userId': 73, 'movieId': 224, 'rating': 3.6, 'timestamp': 1746392656}\n",
      "Sent: {'userId': 33, 'movieId': 242, 'rating': 5.0, 'timestamp': 1746392658}\n",
      "Sent: {'userId': 55, 'movieId': 93, 'rating': 2.7, 'timestamp': 1746392660}\n",
      "Sent: {'userId': 16, 'movieId': 496, 'rating': 2.1, 'timestamp': 1746392661}\n",
      "Sent: {'userId': 87, 'movieId': 342, 'rating': 3.2, 'timestamp': 1746392663}\n",
      "Sent: {'userId': 3, 'movieId': 125, 'rating': 3.5, 'timestamp': 1746392664}\n",
      "Sent: {'userId': 92, 'movieId': 32, 'rating': 4.8, 'timestamp': 1746392665}\n",
      "Sent: {'userId': 34, 'movieId': 288, 'rating': 4.4, 'timestamp': 1746392666}\n",
      "Sent: {'userId': 48, 'movieId': 207, 'rating': 2.8, 'timestamp': 1746392667}\n",
      "Sent: {'userId': 81, 'movieId': 494, 'rating': 2.2, 'timestamp': 1746392668}\n",
      "Sent: {'userId': 13, 'movieId': 18, 'rating': 3.9, 'timestamp': 1746392670}\n",
      "Sent: {'userId': 95, 'movieId': 242, 'rating': 4.1, 'timestamp': 1746392671}\n",
      "Sent: {'userId': 45, 'movieId': 312, 'rating': 1.9, 'timestamp': 1746392672}\n",
      "Sent: {'userId': 49, 'movieId': 23, 'rating': 2.7, 'timestamp': 1746392674}\n",
      "Sent: {'userId': 27, 'movieId': 324, 'rating': 1.9, 'timestamp': 1746392677}\n",
      "Sent: {'userId': 64, 'movieId': 201, 'rating': 1.3, 'timestamp': 1746392679}\n",
      "Sent: {'userId': 56, 'movieId': 478, 'rating': 4.0, 'timestamp': 1746392679}\n",
      "Sent: {'userId': 18, 'movieId': 52, 'rating': 2.6, 'timestamp': 1746392681}\n",
      "Sent: {'userId': 93, 'movieId': 325, 'rating': 4.1, 'timestamp': 1746392683}\n",
      "Sent: {'userId': 16, 'movieId': 412, 'rating': 4.5, 'timestamp': 1746392684}\n",
      "Sent: {'userId': 29, 'movieId': 10, 'rating': 2.6, 'timestamp': 1746392686}\n",
      "Sent: {'userId': 69, 'movieId': 385, 'rating': 1.6, 'timestamp': 1746392687}\n",
      "Sent: {'userId': 2, 'movieId': 469, 'rating': 1.4, 'timestamp': 1746392689}\n",
      "Sent: {'userId': 79, 'movieId': 2, 'rating': 4.9, 'timestamp': 1746392690}\n",
      "Sent: {'userId': 42, 'movieId': 305, 'rating': 1.4, 'timestamp': 1746392692}\n",
      "Sent: {'userId': 98, 'movieId': 486, 'rating': 3.2, 'timestamp': 1746392692}\n",
      "Sent: {'userId': 18, 'movieId': 95, 'rating': 5.0, 'timestamp': 1746392693}\n",
      "Sent: {'userId': 44, 'movieId': 236, 'rating': 3.3, 'timestamp': 1746392694}\n",
      "Sent: {'userId': 71, 'movieId': 128, 'rating': 4.2, 'timestamp': 1746392695}\n",
      "Sent: {'userId': 32, 'movieId': 239, 'rating': 4.2, 'timestamp': 1746392696}\n",
      "Sent: {'userId': 38, 'movieId': 1, 'rating': 3.2, 'timestamp': 1746392698}\n",
      "Sent: {'userId': 97, 'movieId': 44, 'rating': 1.7, 'timestamp': 1746392699}\n",
      "Sent: {'userId': 70, 'movieId': 292, 'rating': 1.7, 'timestamp': 1746392701}\n",
      "Sent: {'userId': 24, 'movieId': 7, 'rating': 4.6, 'timestamp': 1746392702}\n",
      "Sent: {'userId': 24, 'movieId': 195, 'rating': 3.5, 'timestamp': 1746392704}\n",
      "Sent: {'userId': 30, 'movieId': 195, 'rating': 3.3, 'timestamp': 1746392706}\n",
      "Sent: {'userId': 77, 'movieId': 111, 'rating': 3.8, 'timestamp': 1746392708}\n",
      "Total des messages envoyés: 50\n",
      "Sent: {'userId': 49, 'movieId': 204, 'rating': 1.6, 'timestamp': 1746392710}\n",
      "Sent: {'userId': 95, 'movieId': 409, 'rating': 4.5, 'timestamp': 1746392711}\n",
      "Sent: {'userId': 85, 'movieId': 425, 'rating': 1.8, 'timestamp': 1746392713}\n",
      "Sent: {'userId': 73, 'movieId': 451, 'rating': 3.2, 'timestamp': 1746392714}\n",
      "Sent: {'userId': 52, 'movieId': 9, 'rating': 1.9, 'timestamp': 1746392715}\n",
      "Sent: {'userId': 29, 'movieId': 491, 'rating': 1.2, 'timestamp': 1746392717}\n",
      "Sent: {'userId': 19, 'movieId': 75, 'rating': 3.3, 'timestamp': 1746392719}\n",
      "Sent: {'userId': 49, 'movieId': 153, 'rating': 3.4, 'timestamp': 1746392720}\n",
      "Sent: {'userId': 75, 'movieId': 389, 'rating': 4.5, 'timestamp': 1746392721}\n",
      "Sent: {'userId': 77, 'movieId': 95, 'rating': 1.9, 'timestamp': 1746392722}\n",
      "Sent: {'userId': 17, 'movieId': 157, 'rating': 4.1, 'timestamp': 1746392723}\n",
      "Sent: {'userId': 67, 'movieId': 73, 'rating': 1.2, 'timestamp': 1746392725}\n",
      "Sent: {'userId': 15, 'movieId': 300, 'rating': 4.0, 'timestamp': 1746392726}\n",
      "Sent: {'userId': 15, 'movieId': 55, 'rating': 1.9, 'timestamp': 1746392728}\n",
      "Sent: {'userId': 55, 'movieId': 417, 'rating': 2.0, 'timestamp': 1746392729}\n",
      "Sent: {'userId': 37, 'movieId': 296, 'rating': 3.3, 'timestamp': 1746392730}\n",
      "Sent: {'userId': 51, 'movieId': 18, 'rating': 2.8, 'timestamp': 1746392731}\n",
      "Sent: {'userId': 69, 'movieId': 290, 'rating': 1.7, 'timestamp': 1746392733}\n",
      "Sent: {'userId': 85, 'movieId': 407, 'rating': 2.7, 'timestamp': 1746392733}\n",
      "Sent: {'userId': 41, 'movieId': 126, 'rating': 1.3, 'timestamp': 1746392735}\n",
      "Sent: {'userId': 61, 'movieId': 48, 'rating': 2.2, 'timestamp': 1746392736}\n",
      "Sent: {'userId': 75, 'movieId': 252, 'rating': 4.8, 'timestamp': 1746392736}\n",
      "Sent: {'userId': 59, 'movieId': 431, 'rating': 3.2, 'timestamp': 1746392740}\n"
     ]
    }
   ],
   "source": [
    "# simulate_stream.py\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Charger les IDs de films réels si disponible\n",
    "try:\n",
    "    real_movies = []\n",
    "    with open('movies.csv', 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            real_movies.append(int(row['movieId']))\n",
    "    movies = real_movies if real_movies else list(range(1, 500))\n",
    "except:\n",
    "    movies = list(range(1, 500))\n",
    "\n",
    "# Configuration du producteur Kafka\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    value_serializer=lambda v: json.dumps(v).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Données simulées\n",
    "users = list(range(1, 100))\n",
    "\n",
    "# Logs des messages\n",
    "log_file = f\"producer_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "\n",
    "# Boucle d'envoi des messages\n",
    "try:\n",
    "    count = 0\n",
    "    with open(log_file, 'w') as log:\n",
    "        while True:\n",
    "            # Simuler une interaction utilisateur\n",
    "            data = {\n",
    "                \"userId\": random.choice(users),\n",
    "                \"movieId\": random.choice(movies),\n",
    "                \"rating\": round(random.uniform(1, 5), 1),\n",
    "                \"timestamp\": int(time.time())\n",
    "            }\n",
    "            \n",
    "            # Envoyer au topic Kafka\n",
    "            producer.send('MoviesRatings', data)\n",
    "            \n",
    "            # Log du message\n",
    "            log_entry = f\"[{datetime.now().isoformat()}] Message envoyé: {data}\\n\"\n",
    "            log.write(log_entry)\n",
    "            log.flush()\n",
    "            \n",
    "            print(f\"Sent: {data}\")\n",
    "            count += 1\n",
    "            \n",
    "            # Afficher des statistiques périodiquement\n",
    "            if count % 50 == 0:\n",
    "                print(f\"Total des messages envoyés: {count}\")\n",
    "            \n",
    "            # Pause aléatoire pour simuler un trafic plus réaliste\n",
    "            time.sleep(random.uniform(0.5, 2.0))\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\nProduction interrompue. Total des messages envoyés: {count}\")\n",
    "    print(f\"Journal des messages sauvegardé dans: {log_file}\")\n",
    "    producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821433ed-179f-4cd1-afdc-6dcedf26091d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
