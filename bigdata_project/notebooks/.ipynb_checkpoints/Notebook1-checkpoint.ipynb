{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504ee6d4-feb6-4ab0-b7fb-e17163e22a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .set(\"spark.driver.memory\", \"4g\") \\\n",
    "    .set(\"spark.executor.memory\", \"4g\") \\\n",
    "    .set(\"spark.executor.cores\", \"2\") \\\n",
    "    .set(\"spark.driver.maxResultSize\", \"2g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24635d85-087c-4bba-8e1e-4be45c1944da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/30 10:13:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/30 10:13:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BigDataProject\") \\\n",
    "    .config(conf=conf) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c47f821-866a-4702-b969-37efcc2a0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/datasets/movie.csv\",\n",
    "    header=True,        \n",
    "    inferSchema=True    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a4010e-3052-40d1-9315-1f18aa068439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, title: string, genres: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c22ebf5-fcee-4b59-ba18-445274dc3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "rating_df = spark.read.csv(\n",
    "    \"hdfs://namenode:9000/datasets/rating.csv\",\n",
    "    header=True,        \n",
    "    inferSchema=True    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6735f9-1083-442a-8737-5db7e8a1cc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da0fb9b-f0a2-45db-845b-3f259113db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c3c878-37bd-464c-8b1a-6f4b7bc88476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('movieId', IntegerType(), True), StructField('title', StringType(), True), StructField('genres', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "movie_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)\n",
    "])\n",
    "print(movie_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc13a52-dce1-4755-868b-896feb69ad2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('userId', IntegerType(), True), StructField('movie', StringType(), True), StructField('rating', StringType(), True), StructField('timestamp', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "rating_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movie\", StringType(), True),\n",
    "    StructField(\"rating\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True)\n",
    "])\n",
    "print(rating_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac3ddc0-b47f-4604-a821-d1fabb700754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|    148|    1|\n",
      "|    463|    1|\n",
      "|    471|    1|\n",
      "|    496|    1|\n",
      "|    833|    1|\n",
      "|   1088|    1|\n",
      "|   1238|    1|\n",
      "|   1342|    1|\n",
      "|   1580|    1|\n",
      "|   1591|    1|\n",
      "|   1645|    1|\n",
      "|   1829|    1|\n",
      "|   1959|    1|\n",
      "|   2122|    1|\n",
      "|   2142|    1|\n",
      "|   2366|    1|\n",
      "|   2659|    1|\n",
      "|   2866|    1|\n",
      "|   3175|    1|\n",
      "|   3749|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============================================>          (13 + 3) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   148|  128|\n",
      "|   463|   80|\n",
      "|   471|  548|\n",
      "|   496|  168|\n",
      "|   833|   47|\n",
      "|  1088|   60|\n",
      "|  1238|   97|\n",
      "|  1342|   25|\n",
      "|  1580|   42|\n",
      "|  1591|   50|\n",
      "|  1645|  108|\n",
      "|  1829|  288|\n",
      "|  1959|  226|\n",
      "|  2122|  115|\n",
      "|  2142|   29|\n",
      "|  2366|   42|\n",
      "|  2659|  101|\n",
      "|  2866|  940|\n",
      "|  3175|   22|\n",
      "|  3749|   44|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "movies_df.groupBy(\"movieId\").count().show()\n",
    "rating_df.groupBy(\"userId\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c87d39d-4609-45d9-a7b4-ec5c5e0c4fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérification des doublouns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7860b00d-4c87-48aa-ada4-7ab21175282d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doublons dans movies : 27278 vs 27278\n"
     ]
    }
   ],
   "source": [
    "print(\"Doublons dans movies :\", movies_df.count(), \"vs\", movies_df.dropDuplicates().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1714a2e1-fc00-496f-a85d-09eeec165e3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:13:50 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:01 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 26:====================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doublons dans rating : 20000263 vs 20000263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Doublons dans rating :\", rating_df.count(), \"vs\", rating_df.dropDuplicates().count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e3acf-a1aa-4088-8913-1a513a6a2e84",
   "metadata": {},
   "source": [
    "# Vérification des valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03be6427-9cb3-4646-9d69-19aa31ff7bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|       |\n",
      "+-------+\n",
      "\n",
      "+-------+\n",
      "|summary|\n",
      "+-------+\n",
      "|       |\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan, isnull\n",
    "\n",
    "# Pour rating\n",
    "rating_df.select([col(c).isNull().alias(c) for c in rating_df.columns]).summary(\"\").show()\n",
    "\n",
    "# Pour movies\n",
    "movies_df.select([col(c).isNull().alias(c) for c in movies_df.columns]).summary(\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b576c86f-4c29-4659-a2d6-097b0085ef0d",
   "metadata": {},
   "source": [
    "Fussionner les deux df avec Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a07c84-5d1f-4662-af66-ca6b102d0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "|movieId|userId|rating|          timestamp|               title|              genres|\n",
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "|      2|     1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|Adventure|Childre...|\n",
      "|     29|     1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|Adventure|Drama|F...|\n",
      "|     32|     1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|\n",
      "|     47|     1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "|     50|     1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|Crime|Mystery|Thr...|\n",
      "+-------+------+------+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_movies = rating_df.join(movies_df, on=\"movieId\", how=\"inner\")\n",
    "rating_movies.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13977bc6-3180-4c37-b51f-5ecabcf00c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ebf53-ec84-4faa-8316-33c22e6dcb70",
   "metadata": {},
   "source": [
    "#Nombre de lignes distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29591600-5178-4b64-980f-803ea9be5790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/30 10:14:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:25 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:27 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:34 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/04/30 10:14:35 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.select(\"userId\", \"movieId\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0636b235-a096-4e5c-a0bb-708aef706b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "138493"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movies.select(\"movieId\").distinct().count()\n",
    "rating_movies.select(\"userId\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb53341-0df6-4920-aa50-3003442a59e9",
   "metadata": {},
   "source": [
    "# filtrage des notes extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05307bc-eb3d-4878-aaa7-f6968a2e6799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000263"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = rating_df.filter((col(\"rating\") >= 0.5) & (col(\"rating\") <= 5.0))\n",
    "rating_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0bd2e-7e46-49b6-b20a-87e4c4c3f367",
   "metadata": {},
   "source": [
    "# convert datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ffe875-6647-46ca-b8be-08facb7f79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2005-04-02 23:53:47|\n",
      "|2005-04-02 23:31:16|\n",
      "|2005-04-02 23:33:39|\n",
      "|2005-04-02 23:32:07|\n",
      "|2005-04-02 23:29:40|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "rating_movies = rating_movies.withColumn(\"timestamp\", to_timestamp(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\"))\n",
    "\n",
    "rating_movies.printSchema()\n",
    "rating_movies.select(\"timestamp\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb83249-c2a2-41f5-a7d7-3fde559094cf",
   "metadata": {},
   "source": [
    "# Importation du modèle \"ALS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faddf22c-5362-4bcd-92b0-4841231a1c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4885f46a-c1f5-46fe-af95-0ad33c736867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6ad23-8409-4fb0-82ee-ed22081a0840",
   "metadata": {},
   "source": [
    "# Données de train et test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3913391d-ba9a-417d-8292-aff9c1cd9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = rating_movies.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cba760a-9214-4fd0-bfad-11ab375f134d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8231c55-326f-4651-a0ed-716d7d212a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/30 10:15:54 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    rank=10,             # nombre de facteurs latents\n",
    "    maxIter=10,          # nombre d’itérations\n",
    "    regParam=0.1,        # régularisation\n",
    "    numItemBlocks=10,    # Nombre de blocs pour paralléliser le calcul \n",
    "    nonnegative=True\n",
    ")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb536f4-2194-4e42-8961-911ec5157d45",
   "metadata": {},
   "source": [
    "# Evaluation du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02fe2f41-2efc-46b6-a135-3fa860ac1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 272:===================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle:\n",
      "RMSE sur le jeu de test : nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"\\nPerformance du modèle:\")\n",
    "print(f\"RMSE sur le jeu de test : {rmse:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "879d2770-4d9e-4a9e-9377-bc407cc429eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 324:============================================>          (13 + 3) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    31|      1|   3.0|  3.293149|\n",
      "|  8947|      1|   5.0|  3.692583|\n",
      "|  8986|      1|   4.0| 3.4103339|\n",
      "|  9027|      1|   5.0|  3.087177|\n",
      "| 17486|      1|   3.0|  3.586236|\n",
      "| 17536|      1|   3.0|  3.508809|\n",
      "| 17539|      1|   4.0| 3.0576348|\n",
      "| 26273|      1|   3.0| 3.2686825|\n",
      "| 26309|      1|   4.5| 3.3468356|\n",
      "| 35112|      1|   5.0|   4.07642|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test)\n",
    "predictions.select(\"userId\", \"movieId\", \"rating\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1124f76-22c4-45e2-a974-5a6da0445fbc",
   "metadata": {},
   "source": [
    "# Suppression des Nan dans la prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a69ca48e-1e7f-40d0-8c13-497fa437ce16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, col\n",
    "\n",
    "predictions.filter(col(\"prediction\").isNull() | isnan(col(\"prediction\"))).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "463d30db-8611-42dc-9f39-a6587a122e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_clean = predictions.na.drop(subset=[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9196805e-bd13-408c-b118-4b15af8898eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 531:===================================================>   (16 + 1) / 17]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la performance RMSE  : 0.8166866139718709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions_clean)\n",
    "print(f\"la performance RMSE  : {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27dd7f27-b2e9-4279-aa5b-3c5de2cdfe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "model.write().overwrite().save(\"hdfs://namenode:9000/models/als\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c3310c-12c0-4c7f-ab13-fac35ebbc6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
